# Flujo de trabajo básico 

```{r}
#| include: false
library(tidyverse)
library(kableExtra)
library(DiagrammeR)
library(rethinking)
ggplot2::theme_set(ggplot2::theme_light())
```

En esta sección introductoria, veremos una aplicación básica del flujo de
trabajo que seguiremos. El objetivo en este ejemplo es estimar la proporción
de personas que es seropositiva de una enfermedad en una población dada, usando una 
muestra de la población de interés a la que se le aplicó una prueba de seropositivdad.

## Modelo generativo

Consideremos primero qué variables de interés tenemos: $p$, la proporción de
seropositivos en la población, $N$ que es el número de personas a las que les
hicimos la prueba, y $N_{+}$ y $N_{-}$ que cuentan el número de positivos y seronegativos
en la muestra. Supondremos que la prueba da resultados exactos.



Comenzamos construyendo el diagrama que indica cómo influye cada variable en 
otra (nota: no son asociaciones, sino que indican qué variables "escuchan" a otras
para determinar su valor). En este caso, $N$ y $p$ son variable que no depende de ninguna
otra, mientras que $N_{+}$ y $N_{-}$ dependen de $N$ y $p$. 

```{r}
#| out-width: 100%
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.3, rankdir = LR]
  node [shape=circle]
    p
  node [shape=plaintext]
    N
    Npos [label = <N<SUB>+</SUB>>]
    Nneg [label = <N<SUB>-</SUB>>]
    #sens
    #esp
  edge [minlen = 3]
    p -> Npos
    p -> Nneg
    N -> Npos
    N -> Nneg
    #esp -> Pos
    #sens -> Pos
    #esp -> Neg
    #sens -> Neg
{ rank = same; p; N }
{ rank = same; Npos; Nneg}
#{ rank = max; sens; esp}

  
}
")#, width = 200, height = 50)
```

Y ahora construimos el modelo generativo:

```{r}
sim_pos_neg <- function(p = 0.01, N = 20, sens = 1, esp = 1) {
  # verdaderos positivos que capturamos en la muestra
  Pos_verdadero <- rbinom(N, 1, p)
  Neg_verdadero <- 1 - Pos_verdadero
  # positivos observados en la muestra
  Pos <- Pos_verdadero
  #Pos <- map_int(Pos_verdadero, 
  #  \(x) ifelse(x == 1, rbinom(1, 1, sens), rbinom(1, 1, (1 - esp))
  #))
  Neg <- 1 - Pos
  # Observaciones
  tibble(Pos = Pos, Neg = Neg)
}
```

Podemos en primer lugar
hacer algunas pruebas del modelo generativo en casos extremos:

```{r}
set.seed(8212)
sim_pos_neg(p = 0.995, N = 10)
sim_pos_neg(p = 0.005, N = 10)
sim_pos_neg(p = 0.1, N = 1e7) |> pull(Pos) |> mean() |> 
  round(4)
```

Análisis de datos bayesiano

En estadística bayesiana podemos consideramos las posibles explicaciones
(estados de $p$) de los datos, y consideramos como más creíbles aquellas explicaciones
que pueden ocurrir de manera más probable. 

Supongamos entonces una $p$ dada, y que observamos la muestra
$1,0,0,1,0$. La probabilidad de observar esta muestra es entonces

$$p(1-p)(1-p)p(1-p) = p^2(1-p)^3$$
Podemos graficar esta función:

```{r}
p <- seq(0, 1, length.out = 100)
(p^2 * (1 - p)^3) |> 
  tibble(p = p, prob = _) |> 
  ggplot(aes(x = p, y = prob)) +
  geom_line() +
  labs(x = "p", y = "p(D|p)")

```

Esta función no es una densidad de probabilidad sobre $p$, pues no integra a uno.
Sin embargo, podemos normalizarla para que integre a uno. Usando cálculo, podemos
mostrar que la **probabilidad posterior** para $p$ está dada por la densidad

$$ \frac{1}{B(E,F)} p^E(1-p)^F$$
donde $B(E,F) = \frac{(E+F+1)!}{E!F!}$. Esta densidad se llama **beta** con 
parámetros $E+1$ y $F+1$.

```{r}
simular_posterior <- function(muestra, n){
  rbeta(n, sum(muestra$Pos) + 1, sum(muestra$Neg) + 1)
}
```

```{r}
una_muestra <- sim_pos_neg(p = 0.1, N = 100)
simular_posterior(una_muestra, 1000) |> 
  tibble(p = _) |> 
  ggplot(aes(x = p)) +
  geom_histogram()
```





## Modelo generativo: errores de medición 1

Ahora supongamos que la prueba no es perfecta, y que tiene una sensibilidad y
una especificidad conocida.

el diagrama es ahora:

```{r}
#| out-width: 100%
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.3, rankdir = LR]
  node [shape=circle]
    p
  node [shape=plaintext]
    N
    Npos [label = <N<SUB>+</SUB>>]
    Nneg [label = <N<SUB>-</SUB>>]
    #sens
    #esp
  edge [minlen = 3]
    p -> Npos
    p -> Nneg
    N -> Npos
    N -> Nneg
    esp -> Npos
    sens -> Npos
    esp -> Nneg
    sens -> Nneg
{ rank = same; p; N }
{ rank = same; Npos; Nneg}
{ rank = max; sens; esp}
}
")#, width = 200, height = 50)
```

#Y para constuir el modelo generativo notamos que
#la probabilidad de que un individuo sea positivo en la muestra sale
#positivo es:

#$$P(E) = P(E|Pos)P(Pos) + P(E|Neg)P(Neg) = sens*p + (1-esp)*(1-p)$$

Y el modelo generativo es:

```{r}
sim_pos_neg <- function(p = 0.01, N = 20, sens = 1, esp = 1) {
  # verdaderos positivos que capturamos en la muestra
  Pos_verdadero <- rbinom(N, 1, p)
  Neg_verdadero <- 1 - Pos_verdadero
  # positivos observados en la muestra: si es positivo, calculamos
  # la probabilidad de que realmente sea positivo
  sim_tbl <- tibble(Pos_verdadero, Neg_verdadero) |> 
    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |> 
    mutate(Neg = 1 - Pos)
  # Observaciones
  sim_tbl |> select(Pos, Neg)
}
```

Hacemos unas pruebas:

```{r}
set.seed(8212)
sim_pos_neg(p = 0.3, N = 1e7, sens = 0.9, esp = 0.99) |> pull(Pos) |> mean() |> 
  round(4)
sim_pos_neg(p = 0.3, N = 1e7, sens = 1, esp = 1) |> pull(Pos) |> mean() |> 
  round(4)
```

```{r}
simular_posterior <- function(muestra, n, sens = 1, esp = 1){
  p_obs <- rbeta(n, sum(muestra$Pos) + 1, sum(muestra$Neg) + 1)
  p <- (p_obs + esp -1 ) / (sens + esp - 1)
  p
}
```

```{r}
set.seed(88)
una_muestra <- sim_pos_neg(p = 0.3, N = 600, sens = 0.5, esp = 0.99)
mean(una_muestra$Pos)
simular_posterior(una_muestra, 1000, sens = 0.5, esp = 0.99) |> 
  tibble(p = _) |> 
  ggplot(aes(x = p)) +
  geom_histogram()
```

## Modelo generativo: errores de medición 2

Ahora haremos un paso adicional: los valores de sensibilidad y especificidad
generalmente no son conocidos con certeza, sino que son estimados a partir de
una muestra de "estándar de oro". En esta prueba particular,  el kit identificó correctamente como positivos a 103 de 122 personas infectadas,
e identificó correctamente como negativos a 399 de 401 personas no infectadas. 
Consideraremos 122 y 401 como tamaños de muestra fijos y conocidos (las personas
fueron extraídas de otra población). 

```{r}

```{r}

```{r}
#| out-width: 100%
#| code-fold: true
grViz("
digraph {
  graph [ranksep = 0.3, rankdir = LR]
  node [shape=circle]
    p
    esp
    sens
  node [shape=plaintext]
    N
    Npos [label = <N<SUB>+</SUB>>]
    Nneg [label = <N<SUB>-</SUB>>]
  edge [minlen = 3]
    p -> Npos
    p -> Nneg
    N -> Npos
    N -> Nneg
    esp -> Npos
    sens -> Npos
    esp -> Nneg
    sens -> Nneg
{ rank = same; p; N }
{ rank = same; Npos; Nneg}
{ rank = max; sens; esp}
}
")#, width = 200, height = 50)
```

Por los argumentos de arriba, las distribuciones de esp y sens son beta,
y podemos incorporarlas en la simulación de la posterior. Nuestra nueva
función para simular de la posterior es:

```{r}
sim_pos_neg <- function(p = 0.01, N = 20, pos_gold = c(103,122), neg_gold = c(399,401)) {
  sens <- rbeta(1, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)
  esp <- rbeta(1, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)
  # verdaderos positivos que capturamos en la muestra
  Pos_verdadero <- rbinom(N, 1, p)
  Neg_verdadero <- 1 - Pos_verdadero
  # positivos observados en la muestra: si es positivo, calculamos
  # la probabilidad de que realmente sea positivo
  sim_tbl <- tibble(Pos_verdadero, Neg_verdadero) |> 
    mutate(Pos = rbinom(N, 1, Pos_verdadero * sens + Neg_verdadero * (1-esp))) |> 
    mutate(Neg = 1 - Pos)
  # Observaciones
  sim_tbl |> select(Pos, Neg)
}
```

```{r}
simular_posterior <- function(muestra, n, pos_gold = c(103,122), neg_gold = c(399,401)){
  # simulamos sens y especificidad
  sens <- rbeta(n, pos_gold[1] + 1, pos_gold[2] - pos_gold[1] + 1)
  esp <- rbeta(n, neg_gold[1] + 1, neg_gold[2] - neg_gold[1] + 1)
  # simulamos muestra
  p_obs <- rbeta(n, sum(muestra$Pos) + 1, sum(muestra$Neg) + 1)
  p <- (p_obs + esp -1 ) / (sens + esp - 1)
  ifelse(p > 0, p, 0)
}
```


```{r}
set.seed(828)
una_muestra <- sim_pos_neg(p = 0.01, N = 3300)
mean(una_muestra$Pos)
simular_posterior(una_muestra, 1000) |> 
  tibble(p = _) |> 
  ggplot(aes(x = p)) +
  geom_histogram()
```

Y notamos que aún con una muestra relativamente grande, 
el rango de $p$ es considerable: va desde valores cercanos a 0 hasta valores
alrededor de 0.025-0.03.
